<!DOCTYPE html> <html><head>
		<title>Multithreading and Multiprocessors</title>
		<base href="../../../">
		<meta id="root-path" root-path="../../../">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes, minimum-scale=1.0, maximum-scale=5.0">
		<meta charset="UTF-8">
		<meta name="description" content="Vault - Multithreading and Multiprocessors">
		<meta property="og:title" content="Multithreading and Multiprocessors">
		<meta property="og:description" content="Vault - Multithreading and Multiprocessors">
		<meta property="og:type" content="website">
		<meta property="og:url" content="universitÃ /aca/notes/multithreading-and-multiprocessors.html">
		<meta property="og:image" content="lib/media/multithreading-and-multiprocessors.png">
		<meta property="og:site_name" content="Vault">
		<link rel="alternate" type="application/rss+xml" title="RSS Feed" href="lib/rss.xml"><script async="" id="webpage-script" src="lib/scripts/webpage.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script type="module" async="" id="graph-view-script" src="lib/scripts/graph-view.js"></script><script async="" id="graph-wasm-script" src="lib/scripts/graph-wasm.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="graph-render-worker-script" src="lib/scripts/graph-render-worker.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="tinycolor-script" src="lib/scripts/tinycolor.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="pixi-script" src="https://cdnjs.cloudflare.com/ajax/libs/pixi.js/7.4.0/pixi.min.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="minisearch-script" src="https://cdn.jsdelivr.net/npm/minisearch@6.3.0/dist/umd/index.min.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><link rel="icon" href="lib/media/favicon.png"><script async="" id="graph-data-script" src="lib/scripts/graph-data.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><style>body{--line-width:40em;--line-width-adaptive:40em;--file-line-width:40em;--sidebar-width:min(20em, 80vw);--collapse-arrow-size:11px;--tree-horizontal-spacing:0.6em;--tree-vertical-spacing:0.6em;--sidebar-margin:12px}.sidebar{height:100%;min-width:calc(var(--sidebar-width) + var(--divider-width-hover));max-width:calc(var(--sidebar-width) + var(--divider-width-hover));font-size:14px;z-index:10;position:relative;overflow:hidden;transition:min-width ease-in-out,max-width ease-in-out;transition-duration:.2s;contain:size}.sidebar-left{left:0}.sidebar-right{right:0}.sidebar.is-collapsed{min-width:0;max-width:0}body.floating-sidebars .sidebar{position:absolute}.sidebar-content{height:100%;min-width:calc(var(--sidebar-width) - var(--divider-width-hover));top:0;padding:var(--sidebar-margin);padding-top:4em;line-height:var(--line-height-tight);background-color:var(--background-secondary);transition:background-color,border-right,border-left,box-shadow;transition-duration:var(--color-fade-speed);transition-timing-function:ease-in-out;position:absolute;display:flex;flex-direction:column}.sidebar:not(.is-collapsed) .sidebar-content{min-width:calc(max(100%,var(--sidebar-width)) - 3px);max-width:calc(max(100%,var(--sidebar-width)) - 3px)}.sidebar-left .sidebar-content{left:0;border-top-right-radius:var(--radius-l);border-bottom-right-radius:var(--radius-l)}.sidebar-right .sidebar-content{right:0;border-top-left-radius:var(--radius-l);border-bottom-left-radius:var(--radius-l)}.sidebar:has(.sidebar-content:empty):has(.topbar-content:empty){display:none}.sidebar-topbar{height:2em;width:var(--sidebar-width);top:var(--sidebar-margin);padding-inline:var(--sidebar-margin);z-index:1;position:fixed;display:flex;align-items:center;transition:width ease-in-out;transition-duration:inherit}.sidebar.is-collapsed .sidebar-topbar{width:calc(2.3em + var(--sidebar-margin) * 2)}.sidebar .sidebar-topbar.is-collapsed{width:0}.sidebar-left .sidebar-topbar{left:0}.sidebar-right .sidebar-topbar{right:0}.topbar-content{overflow:hidden;overflow:clip;width:100%;height:100%;display:flex;align-items:center;transition:inherit}.sidebar.is-collapsed .topbar-content{width:0;transition:inherit}.clickable-icon.sidebar-collapse-icon{background-color:transparent;color:var(--icon-color-focused);padding:0!important;margin:0!important;height:100%!important;width:2.3em!important;margin-inline:0.14em!important;position:absolute}.sidebar-left .clickable-icon.sidebar-collapse-icon{transform:rotateY(180deg);right:var(--sidebar-margin)}.sidebar-right .clickable-icon.sidebar-collapse-icon{transform:rotateY(180deg);left:var(--sidebar-margin)}.clickable-icon.sidebar-collapse-icon svg.svg-icon{width:100%;height:100%}.sidebar-section-header{margin:0 0 1em 0;text-transform:uppercase;letter-spacing:.06em;font-weight:600}body{transition:background-color var(--color-fade-speed) ease-in-out}.webpage-container{display:flex;flex-direction:row;height:100%;width:100%;align-items:stretch;justify-content:center}.document-container{opacity:1;flex-basis:100%;max-width:100%;width:100%;height:100%;display:flex;flex-direction:column;align-items:center;transition:opacity .2s ease-in-out;contain:inline-size}.hide{opacity:0;transition:opacity .2s ease-in-out}.document-container>.markdown-preview-view{margin:var(--sidebar-margin);margin-bottom:0;width:100%;width:-webkit-fill-available;width:-moz-available;width:fill-available;background-color:var(--background-primary);transition:background-color var(--color-fade-speed) ease-in-out;border-top-right-radius:var(--window-radius,var(--radius-m));border-top-left-radius:var(--window-radius,var(--radius-m));overflow-x:hidden!important;overflow-y:auto!important;display:flex!important;flex-direction:column!important;align-items:center!important;contain:inline-size}.document-container>.markdown-preview-view>.markdown-preview-sizer{padding-bottom:80vh!important;width:100%!important;max-width:var(--line-width)!important;flex-basis:var(--line-width)!important;transition:background-color var(--color-fade-speed) ease-in-out;contain:inline-size}.markdown-rendered img:not([width]),.view-content img:not([width]){max-width:100%;outline:0}.document-container>.view-content.embed{display:flex;padding:1em;height:100%;width:100%;align-items:center;justify-content:center}.document-container>.view-content.embed>*{max-width:100%;max-height:100%;object-fit:contain}:has(> :is(.math,table)){overflow-x:auto!important}.document-container>.view-content{overflow-x:auto;contain:content;padding:0;margin:0;height:100%}.scroll-highlight{position:absolute;width:100%;height:100%;pointer-events:none;z-index:1000;background-color:hsla(var(--color-accent-hsl),.25);opacity:0;padding:1em;inset:50%;translate:-50% -50%;border-radius:var(--radius-s)}</style><script defer="">async function loadIncludes(){if("file:"!=location.protocol){let e=document.querySelectorAll("include");for(let t=0;t<e.length;t++){let o=e[t],l=o.getAttribute("src");try{const e=await fetch(l);if(!e.ok){console.log("Could not include file: "+l),o?.remove();continue}let t=await e.text(),n=document.createRange().createContextualFragment(t),i=Array.from(n.children);for(let e of i)e.classList.add("hide"),e.style.transition="opacity 0.5s ease-in-out",setTimeout((()=>{e.classList.remove("hide")}),10);o.before(n),o.remove(),console.log("Included file: "+l)}catch(e){o?.remove(),console.log("Could not include file: "+l,e);continue}}}else{if(document.querySelectorAll("include").length>0){var e=document.createElement("div");e.id="error",e.textContent="Web server exports must be hosted on an http / web server to be viewed correctly.",e.style.position="fixed",e.style.top="50%",e.style.left="50%",e.style.transform="translate(-50%, -50%)",e.style.fontSize="1.5em",e.style.fontWeight="bold",e.style.textAlign="center",document.body.appendChild(e),document.querySelector(".document-container")?.classList.remove("hide")}}}document.addEventListener("DOMContentLoaded",(()=>{loadIncludes()}));let isFileProtocol="file:"==location.protocol;function waitLoadScripts(e,t){let o=e.map((e=>document.getElementById(e+"-script"))),l=0;!function e(){let n=o[l];l++,n&&"true"!=n.getAttribute("loaded")||l<o.length&&e(),l<o.length?n.addEventListener("load",e):t()}()}</script><link rel="stylesheet" href="lib/styles/obsidian.css"><link rel="preload" href="lib/styles/global-variable-styles.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="lib/styles/global-variable-styles.css"></noscript><link rel="preload" href="lib/styles/main-styles.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="lib/styles/main-styles.css"></noscript></head><body class="publish css-settings-manager theme-light show-inline-title show-ribbon"><script defer="">let theme=localStorage.getItem("theme")||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light");"dark"==theme?(document.body.classList.add("theme-dark"),document.body.classList.remove("theme-light")):(document.body.classList.add("theme-light"),document.body.classList.remove("theme-dark")),window.innerWidth<480?document.body.classList.add("is-phone"):window.innerWidth<768?document.body.classList.add("is-tablet"):window.innerWidth<1024?document.body.classList.add("is-small-screen"):document.body.classList.add("is-large-screen")</script><div class="webpage-container workspace"><div class="sidebar-left sidebar"><div class="sidebar-handle"></div><div class="sidebar-topbar"><div class="topbar-content"><label class="theme-toggle-container" for="theme_toggle"><input class="theme-toggle-input" type="checkbox" id="theme_toggle"><div class="toggle-background"></div></label></div><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div><div class="sidebar-content"><div class="search-input-container"><input enterkeyhint="search" type="search" spellcheck="false" placeholder="Search..."><div class="search-input-clear-button" aria-label="Clear search"></div></div><include src="lib/html/file-tree.html"></include></div><script defer="">let ls = document.querySelector(".sidebar-left"); ls.classList.add("is-collapsed"); if (window.innerWidth > 768) ls.classList.remove("is-collapsed"); ls.style.setProperty("--sidebar-width", localStorage.getItem("sidebar-left-width"));</script></div><div class="document-container markdown-reading-view hide"><div class="markdown-preview-view markdown-rendered allow-fold-headings allow-fold-lists is-readable-line-width"><style id="MJX-CHTML-styles">mjx-c.mjx-c1D444.TEX-I::before{padding:.704em .791em .194em 0;content:"Q"}mjx-c.mjx-c1D457.TEX-I::before{padding:.661em .412em .204em 0;content:"j"}mjx-c.mjx-c50::before{padding:.683em .681em 0 0;content:"P"}mjx-c.mjx-c43::before{padding:.705em .722em .021em 0;content:"C"}mjx-c.mjx-c49::before{padding:.683em .361em 0 0;content:"I"}mjx-c.mjx-c44::before{padding:.683em .764em 0 0;content:"D"}mjx-c.mjx-c7A::before{padding:.431em .444em 0 0;content:"z"}mjx-c.mjx-c1D450.TEX-I::before{padding:.442em .433em .011em 0;content:"c"}mjx-c.mjx-c1D45C.TEX-I::before{padding:.441em .485em .011em 0;content:"o"}mjx-c.mjx-c1D462.TEX-I::before{padding:.442em .572em .011em 0;content:"u"}mjx-c.mjx-c1D452.TEX-I::before{padding:.442em .466em .011em 0;content:"e"}mjx-c.mjx-c1D45F.TEX-I::before{padding:.442em .451em .011em 0;content:"r"}mjx-c.mjx-c2265::before{padding:.636em .778em .138em 0;content:"â¥"}mjx-c.mjx-cD7::before{padding:.491em .778em 0 0;content:"Ã"}mjx-c.mjx-c2C::before{padding:.121em .278em .194em 0;content:","}mjx-mfrac{display:inline-block;text-align:left}mjx-frac{display:inline-block;vertical-align:.17em;padding:0 .22em}mjx-frac[type="d"]{vertical-align:.04em}mjx-frac[delims]{padding:0 .1em}mjx-frac[atop]{padding:0 .12em}mjx-frac[atop][delims]{padding:0}mjx-dtable{display:inline-table;width:100%}mjx-dtable>*{font-size:2000%}mjx-dbox{display:block;font-size:5%}mjx-num{display:block;text-align:center}mjx-den{display:block;text-align:center}mjx-mfrac[bevelled]>mjx-num{display:inline-block}mjx-mfrac[bevelled]>mjx-den{display:inline-block}mjx-den[align=right],mjx-num[align=right]{text-align:right}mjx-den[align=left],mjx-num[align=left]{text-align:left}mjx-nstrut{display:inline-block;height:.054em;width:0;vertical-align:-.054em}mjx-nstrut[type="d"]{height:.217em;vertical-align:-.217em}mjx-dstrut{display:inline-block;height:.505em;width:0}mjx-dstrut[type="d"]{height:.726em}mjx-line{display:block;box-sizing:border-box;min-height:1px;height:.06em;border-top:.06em solid;margin:.06em -.1em;overflow:hidden}mjx-line[type="d"]{margin:.18em -.1em}mjx-mrow{display:inline-block;text-align:left}mjx-c.mjx-c53::before{padding:.705em .556em .022em 0;content:"S"}mjx-c.mjx-c64::before{padding:.694em .556em .011em 0;content:"d"}mjx-c.mjx-c75::before{padding:.442em .556em .011em 0;content:"u"}mjx-c.mjx-c76::before{padding:.431em .528em .011em 0;content:"v"}mjx-c.mjx-c45::before{padding:.68em .681em 0 0;content:"E"}mjx-c.mjx-c78::before{padding:.431em .528em 0 0;content:"x"}mjx-c.mjx-c77::before{padding:.431em .722em .011em 0;content:"w"}mjx-c.mjx-c46::before{padding:.68em .653em 0 0;content:"F"}mjx-msub{display:inline-block;text-align:left}mjx-msup{display:inline-block;text-align:left}mjx-munderover{display:inline-block;text-align:left}mjx-munderover:not([limits=false]){padding-top:.1em}mjx-munderover:not([limits=false])>*{display:block}mjx-msubsup{display:inline-block;text-align:left}mjx-script{display:inline-block;padding-right:.05em;padding-left:.033em}mjx-script>mjx-spacer{display:block}mjx-texatom{display:inline-block;text-align:left}mjx-mtext{display:inline-block;text-align:left}mjx-mn{display:inline-block;text-align:left}mjx-c.mjx-c1D44A.TEX-I::before{padding:.683em 1.048em .022em 0;content:"W"}mjx-c.mjx-c28::before{padding:.75em .389em .25em 0;content:"("}mjx-c.mjx-c1D467.TEX-I::before{padding:.442em .465em .011em 0;content:"z"}mjx-c.mjx-c29::before{padding:.75em .389em .25em 0;content:")"}mjx-c.mjx-c1D437.TEX-I::before{padding:.683em .828em 0 0;content:"D"}mjx-c.mjx-c1D44F.TEX-I::before{padding:.694em .429em .011em 0;content:"b"}mjx-c.mjx-c1D456.TEX-I::before{padding:.661em .345em .011em 0;content:"i"}mjx-c.mjx-c1D45B.TEX-I::before{padding:.442em .6em .011em 0;content:"n"}mjx-c.mjx-c2211.TEX-S1::before{padding:.75em 1.056em .25em 0;content:"â"}mjx-c.mjx-c69::before{padding:.669em .278em 0 0;content:"i"}mjx-c.mjx-c6E::before{padding:.442em .556em 0 0;content:"n"}mjx-c.mjx-c66::before{padding:.705em .372em 0 0;content:"f"}mjx-c.mjx-c1D461.TEX-I::before{padding:.626em .361em .011em 0;content:"t"}mjx-c.mjx-c3D::before{padding:.583em .778em .082em 0;content:"="}mjx-c.mjx-c73::before{padding:.448em .394em .011em 0;content:"s"}mjx-c.mjx-c6D::before{padding:.442em .833em 0 0;content:"m"}mjx-c.mjx-c74::before{padding:.615em .389em .01em 0;content:"t"}mjx-c.mjx-c68::before{padding:.694em .556em 0 0;content:"h"}mjx-c.mjx-c20::before{padding:0 .25em 0 0;content:" "}mjx-c.mjx-c2B::before{padding:.583em .778em .082em 0;content:"+"}mjx-c.mjx-c6F::before{padding:.448em .5em .01em 0;content:"o"}mjx-c.mjx-c65::before{padding:.448em .444em .011em 0;content:"e"}mjx-c.mjx-c72::before{padding:.442em .392em 0 0;content:"r"}mjx-c.mjx-c70::before{padding:.442em .556em .194em 0;content:"p"}mjx-c.mjx-c62::before{padding:.694em .556em .011em 0;content:"b"}mjx-c.mjx-c6C::before{padding:.694em .278em 0 0;content:"l"}mjx-c.mjx-c63::before{padding:.448em .444em .011em 0;content:"c"}mjx-c.mjx-c61::before{padding:.448em .5em .011em 0;content:"a"}mjx-c.mjx-c1D714.TEX-I::before{padding:.443em .622em .011em 0;content:"Ï"}mjx-c.mjx-c2217::before{padding:.465em .5em 0 0;content:"â"}mjx-c.mjx-c32::before{padding:.666em .5em 0 0;content:"2"}mjx-c.mjx-c1D458.TEX-I::before{padding:.694em .521em .011em 0;content:"k"}mjx-c.mjx-c30::before{padding:.666em .5em .022em 0;content:"0"}mjx-c.mjx-c1D460.TEX-I::before{padding:.442em .469em .01em 0;content:"s"}mjx-c.mjx-c1D45A.TEX-I::before{padding:.442em .878em .011em 0;content:"m"}mjx-c.mjx-c210E.TEX-I::before{padding:.694em .576em .011em 0;content:"h"}mjx-c.mjx-c31::before{padding:.666em .5em 0 0;content:"1"}mjx-c.mjx-c1D449.TEX-I::before{padding:.683em .769em .022em 0;content:"V"}mjx-container[jax=CHTML]{line-height:0}mjx-container [space="1"]{margin-left:.111em}mjx-container [space="2"]{margin-left:.167em}mjx-container [space="3"]{margin-left:.222em}mjx-container [space="4"]{margin-left:.278em}mjx-container [space="5"]{margin-left:.333em}mjx-container [rspace="1"]{margin-right:.111em}mjx-container [rspace="2"]{margin-right:.167em}mjx-container [rspace="3"]{margin-right:.222em}mjx-container [rspace="4"]{margin-right:.278em}mjx-container [rspace="5"]{margin-right:.333em}mjx-container [size="s"]{font-size:70.7%}mjx-container [size=ss]{font-size:50%}mjx-container [size=Tn]{font-size:60%}mjx-container [size=sm]{font-size:85%}mjx-container [size=lg]{font-size:120%}mjx-container [size=Lg]{font-size:144%}mjx-container [size=LG]{font-size:173%}mjx-container [size=hg]{font-size:207%}mjx-container [size=HG]{font-size:249%}mjx-container [width=full]{width:100%}mjx-box{display:inline-block}mjx-block{display:block}mjx-itable{display:inline-table}mjx-row{display:table-row}mjx-row>*{display:table-cell}mjx-mtext{display:inline-block}mjx-mstyle{display:inline-block}mjx-merror{display:inline-block;color:red;background-color:#ff0}mjx-mphantom{visibility:hidden}mjx-assistive-mml{top:0;left:0;clip:rect(1px,1px,1px,1px);user-select:none;position:absolute!important;padding:1px 0 0!important;border:0!important;display:block!important;width:auto!important;overflow:hidden!important}mjx-assistive-mml[display=block]{width:100%!important}mjx-math{display:inline-block;text-align:left;line-height:0;text-indent:0;font-style:normal;font-weight:400;font-size:100%;font-size-adjust:none;letter-spacing:normal;border-collapse:collapse;overflow-wrap:normal;word-spacing:normal;white-space:nowrap;direction:ltr;padding:1px 0}mjx-container[jax=CHTML][display=true]{display:block;text-align:center;margin:1em 0}mjx-container[jax=CHTML][display=true][width=full]{display:flex}mjx-container[jax=CHTML][display=true] mjx-math{padding:0}mjx-container[jax=CHTML][justify=left]{text-align:left}mjx-container[jax=CHTML][justify=right]{text-align:right}mjx-mi{display:inline-block;text-align:left}mjx-c{display:inline-block}mjx-utext{display:inline-block;padding:.75em 0 .2em}mjx-mo{display:inline-block;text-align:left}mjx-stretchy-h{display:inline-table;width:100%}mjx-stretchy-h>*{display:table-cell;width:0}mjx-stretchy-h>*>mjx-c{display:inline-block;transform:scaleX(1)}mjx-stretchy-h>*>mjx-c::before{display:inline-block;width:initial}mjx-stretchy-h>mjx-ext{overflow:clip visible;width:100%}mjx-stretchy-h>mjx-ext>mjx-c::before{transform:scaleX(500)}mjx-stretchy-h>mjx-ext>mjx-c{width:0}mjx-stretchy-h>mjx-beg>mjx-c{margin-right:-.1em}mjx-stretchy-h>mjx-end>mjx-c{margin-left:-.1em}mjx-stretchy-v{display:inline-block}mjx-stretchy-v>*{display:block}mjx-stretchy-v>mjx-beg{height:0}mjx-stretchy-v>mjx-end>mjx-c{display:block}mjx-stretchy-v>*>mjx-c{transform:scaleY(1);transform-origin:left center;overflow:hidden}mjx-stretchy-v>mjx-ext{display:block;height:100%;box-sizing:border-box;border:0 solid transparent;overflow:visible clip}mjx-stretchy-v>mjx-ext>mjx-c::before{width:initial;box-sizing:border-box}mjx-stretchy-v>mjx-ext>mjx-c{transform:scaleY(500) translateY(.075em);overflow:visible}mjx-mark{display:inline-block;height:0}mjx-c::before{display:block;width:0}.MJX-TEX{font-family:MJXZERO,MJXTEX}.TEX-B{font-family:MJXZERO,MJXTEX-B}.TEX-I{font-family:MJXZERO,MJXTEX-I}.TEX-MI{font-family:MJXZERO,MJXTEX-MI}.TEX-BI{font-family:MJXZERO,MJXTEX-BI}.TEX-S1{font-family:MJXZERO,MJXTEX-S1}.TEX-S2{font-family:MJXZERO,MJXTEX-S2}.TEX-S3{font-family:MJXZERO,MJXTEX-S3}.TEX-S4{font-family:MJXZERO,MJXTEX-S4}.TEX-A{font-family:MJXZERO,MJXTEX-A}.TEX-C{font-family:MJXZERO,MJXTEX-C}.TEX-CB{font-family:MJXZERO,MJXTEX-CB}.TEX-FR{font-family:MJXZERO,MJXTEX-FR}.TEX-FRB{font-family:MJXZERO,MJXTEX-FRB}.TEX-SS{font-family:MJXZERO,MJXTEX-SS}.TEX-SSB{font-family:MJXZERO,MJXTEX-SSB}.TEX-SSI{font-family:MJXZERO,MJXTEX-SSI}.TEX-SC{font-family:MJXZERO,MJXTEX-SC}.TEX-T{font-family:MJXZERO,MJXTEX-T}.TEX-V{font-family:MJXZERO,MJXTEX-V}.TEX-VB{font-family:MJXZERO,MJXTEX-VB}mjx-stretchy-h mjx-c,mjx-stretchy-v mjx-c{font-family:MJXZERO,MJXTEX-S1,MJXTEX-S4,MJXTEX,MJXTEX-A!important}@font-face{font-family:MJXZERO;src:url("lib/fonts/mathjax_zero.woff") format("woff")}@font-face{font-family:MJXTEX;src:url("lib/fonts/mathjax_main-regular.woff") format("woff")}@font-face{font-family:MJXTEX-B;src:url("lib/fonts/mathjax_main-bold.woff") format("woff")}@font-face{font-family:MJXTEX-I;src:url("lib/fonts/mathjax_math-italic.woff") format("woff")}@font-face{font-family:MJXTEX-MI;src:url("lib/fonts/mathjax_main-italic.woff") format("woff")}@font-face{font-family:MJXTEX-BI;src:url("lib/fonts/mathjax_math-bolditalic.woff") format("woff")}@font-face{font-family:MJXTEX-S1;src:url("lib/fonts/mathjax_size1-regular.woff") format("woff")}@font-face{font-family:MJXTEX-S2;src:url("lib/fonts/mathjax_size2-regular.woff") format("woff")}@font-face{font-family:MJXTEX-S3;src:url("lib/fonts/mathjax_size3-regular.woff") format("woff")}@font-face{font-family:MJXTEX-S4;src:url("lib/fonts/mathjax_size4-regular.woff") format("woff")}@font-face{font-family:MJXTEX-A;src:url("lib/fonts/mathjax_ams-regular.woff") format("woff")}@font-face{font-family:MJXTEX-C;src:url("lib/fonts/mathjax_calligraphic-regular.woff") format("woff")}@font-face{font-family:MJXTEX-CB;src:url("lib/fonts/mathjax_calligraphic-bold.woff") format("woff")}@font-face{font-family:MJXTEX-FR;src:url("lib/fonts/mathjax_fraktur-regular.woff") format("woff")}@font-face{font-family:MJXTEX-FRB;src:url("lib/fonts/mathjax_fraktur-bold.woff") format("woff")}@font-face{font-family:MJXTEX-SS;src:url("lib/fonts/mathjax_sansserif-regular.woff") format("woff")}@font-face{font-family:MJXTEX-SSB;src:url("lib/fonts/mathjax_sansserif-bold.woff") format("woff")}@font-face{font-family:MJXTEX-SSI;src:url("lib/fonts/mathjax_sansserif-italic.woff") format("woff")}@font-face{font-family:MJXTEX-SC;src:url("lib/fonts/mathjax_script-regular.woff") format("woff")}@font-face{font-family:MJXTEX-T;src:url("lib/fonts/mathjax_typewriter-regular.woff") format("woff")}@font-face{font-family:MJXTEX-V;src:url("lib/fonts/mathjax_vector-regular.woff") format("woff")}@font-face{font-family:MJXTEX-VB;src:url("lib/fonts/mathjax_vector-bold.woff") format("woff")}mjx-c.mjx-c1D447.TEX-I::before{padding:.677em .704em 0 0;content:"T"}mjx-c.mjx-c2212::before{padding:.583em .778em .082em 0;content:"â"}mjx-c.mjx-c1D446.TEX-I::before{padding:.705em .645em .022em 0;content:"S"}</style><div class="markdown-preview-sizer markdown-preview-section"><h1 class="page-title heading inline-title" id="Multithreading and Multiprocessors">Multithreading and Multiprocessors</h1><div class="el-p"><p dir="auto"><a href="?query=tag:generated" class="tag" target="_blank" rel="noopener nofollow">#generated</a> </p></div><div class="el-p"><p dir="auto"><a data-tooltip-position="top" aria-label="12.ACA25-MultiThreadsProcessors_v2.pdf" data-href="12.ACA25-MultiThreadsProcessors_v2.pdf" href="universitÃ /aca/12.aca25-multithreadsprocessors_v2.pdf" class="internal-link" target="_self" rel="noopener nofollow">source</a></p></div><div class="el-h2 heading-wrapper"><h2 data-heading="1. The Evolution of Processor Performance" dir="auto" class="heading" id="1._The_Evolution_of_Processor_Performance"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>1. The Evolution of Processor Performance</h2><div class="heading-children"><div class="el-p"><p dir="auto">The history of computer processor development shows a clear pattern of changing approaches to performance improvement. In the 1980s, the computing industry saw significant expansion of superscalar processors with impressive performance gains of around 50%. During this period, transistors were primarily used to create implicit parallelism through pipelined processors, which dramatically reduced cycles per instruction (CPI) from 10 to 1.</p></div><div class="el-p"><p dir="auto">By the 1990s, the industry entered an era of diminishing returns. Engineers worked to exploit implicit parallelism to its fullest potential through techniques like 2-6 way issue capabilities, out-of-order execution, and advanced branch prediction. While these innovations further reduced CPI from 1 to approximately 0.5, the performance improvements fell below expectations. This disappointing reality led to delayed and even canceled processor projects.</p></div><div class="el-p"><p dir="auto">The 2000s marked a fundamental shift in approach with the beginning of the multicore era, which emphasized explicit parallelism. While the number of transistors continued to follow <a data-tooltip-position="top" aria-label="Moore's law" data-href="Moore's law" href="uncomplete-notes/moore's-law.html" class="internal-link" target="_self" rel="noopener nofollow">Moore's Law</a>, both processor frequency and performance per core reached a plateau. This ceiling was primarily due to heat dissipation problems â further increases in frequency would generate too much heat to be practical. This limitation led processor designers to stop focusing on improving single cores and instead develop parallel core architectures.</p></div></div></div><div class="el-h2 heading-wrapper"><h2 data-heading="2. Why Traditional Processors Hit Performance Limits" dir="auto" class="heading" id="2._Why_Traditional_Processors_Hit_Performance_Limits"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>2. Why Traditional Processors Hit Performance Limits</h2><div class="heading-children"><div class="el-p"><p dir="auto">Modern processors often fail to fully utilize their execution resources due to a combination of challenges rather than a single problem. Memory conflicts, control hazards, branch misprediction, and cache misses all contribute to processor inefficiency. Addressing these issues individually has proven to have limited effectiveness. What's needed is a comprehensive latency-tolerance solution that can hide all sources of latency to significantly impact performance.</p></div></div></div><div class="el-h2 heading-wrapper"><h2 data-heading="3. Parallel Programming: The Fundamental Concepts" dir="auto" class="heading" id="3._Parallel_Programming:_The_Fundamental_Concepts"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>3. Parallel Programming: The Fundamental Concepts</h2><div class="heading-children"><div class="el-p"><p dir="auto">Explicit parallelism requires software developers to structure applications into concurrent tasks that can communicate with each other. Operating systems provide support for different types of tasks, with processes and threads being the most important and frequently used.</p></div><div class="el-p"><p dir="auto">A process is a complete execution entity with its own isolated memory space and resources. In contrast, a thread is a lighter execution unit that shares memory with other threads within the same process. Threads within a process can communicate more efficiently than separate processes.</p></div><div class="el-p"><p dir="auto">Operating systems implement multitasking differently depending on the processor architecture:</p></div><div class="el-ul"><ul>
<li data-line="0" dir="auto">Single core processors</li>
<li data-line="1" dir="auto">Single core processors with multithreading support</li>
<li data-line="2" dir="auto">Multicore processors</li>
</ul></div><div class="el-p"><p dir="auto">Understanding the distinction between a process as an execution entity and a thread as a hardware entity is crucial for effective parallel programming.</p></div></div></div><div class="el-h2 heading-wrapper"><h2 data-heading="4. Understanding Multithreaded Execution" dir="auto" class="heading" id="4._Understanding_Multithreaded_Execution"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>4. Understanding Multithreaded Execution</h2><div class="heading-children"><div class="el-p"><p dir="auto">Multithreading allows multiple threads to share the functional units of a single processor through overlapping execution. For this to work, the processor must duplicate independent state for each thread, including separate register files, program counters (PC), and, for independent programs, separate page tables.</p></div><div class="el-p"><p dir="auto">Memory is shared through virtual memory mechanisms that already support multiple processes. The hardware enables fast thread switching, which is much faster than a full process switchâtaking hundreds to thousands of clock cycles rather than the substantially longer time needed for process switching.</p></div><div class="el-p"><p dir="auto">Thread switching can occur in different ways, depending on the implementation:</p></div><div class="el-ul"><ul>
<li data-line="0" dir="auto">Fine-grained multithreading switches between threads at each instruction</li>
<li data-line="1" dir="auto">Coarse-grained multithreading switches only when a thread is stalled, such as during a cache miss</li>
</ul></div></div></div><div class="el-h2 heading-wrapper"><h2 data-heading="5. Thread-Level Parallelism (TLP) Approaches" dir="auto" class="heading" id="5._Thread-Level_Parallelism_(TLP)_Approaches"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>5. Thread-Level Parallelism (TLP) Approaches</h2><div class="heading-children"><div class="el-h3 heading-wrapper"><h3 data-heading="Fine-Grained Multithreading" dir="auto" class="heading" id="Fine-Grained_Multithreading"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>Fine-Grained Multithreading</h3><div class="heading-children"><div class="el-p"><p dir="auto">In fine-grained multithreading, the processor switches from one thread to another at each instruction. This creates an interleaved execution of multiple threads, often taking turns and skipping threads that are stalled. To support this rapid switching, the CPU must be able to change threads at every clock cycle, which requires duplication of hardware resources.</p></div></div></div><div class="el-h3 heading-wrapper"><h3 data-heading="Coarse-Grained Multithreading" dir="auto" class="heading" id="Coarse-Grained_Multithreading"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>Coarse-Grained Multithreading</h3><div class="heading-children"><div class="el-p"><p dir="auto">Coarse-grained multithreading only switches from one thread to another during long stalls, such as when there's a miss in the second-level cache. Since multiple threads share many system resources like architectural registers, switching context requires several clock cycles.</p></div><div class="el-p"><p dir="auto">The primary advantage of coarse-grained multithreading is that under normal conditions, a single thread's performance isn't reduced. There's no need for extremely fast thread-switching mechanisms, and threads don't slow down since instructions from other threads are only issued during costly stalls.</p></div><div class="el-p"><p dir="auto">However, this approach has a significant disadvantage: it doesn't reduce throughput loss for short stalls. When the CPU executes instructions from a single thread and encounters a stall, it must empty the pipeline before starting execution of a new thread.</p></div></div></div></div></div><div class="el-h2 heading-wrapper"><h2 data-heading="6. Combining ILP and TLP: Simultaneous Multithreading" dir="auto" class="heading" id="6._Combining_ILP_and_TLP:_Simultaneous_Multithreading"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>6. Combining ILP and TLP: Simultaneous Multithreading</h2><div class="heading-children"><div class="el-p"><p dir="auto">Thread-Level Parallelism (TLP) and Instruction-Level Parallelism (ILP) exploit different kinds of parallel structures in a program. The question arises: could a processor designed for ILP also exploit TLP? In ILP-oriented processors, functional units often sit idle due to stalls or dependencies in the code. Could TLP provide a source of independent instructions to keep the processor busy during these stalls and utilize otherwise idle functional units?</p></div><div class="el-p"><p dir="auto">Simultaneous Multithreading (SMT) answers this question by using the resources of one superscalar processor to exploit both ILP and TLP simultaneously. The key insight is that modern CPUs have more functional resources than a single thread can effectively use. Through register renaming and dynamic scheduling, instructions from different threads can be issued without concerns about dependencies, as these are resolved by the dynamic scheduling hardware.</p></div><div class="el-h3 heading-wrapper"><h3 data-heading="How SMT Works" dir="auto" class="heading" id="How_SMT_Works"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>How SMT Works</h3><div class="heading-children"><div class="el-p"><p dir="auto">SMT takes advantage of the fact that dynamically scheduled processors already have many hardware mechanisms that support multithreading:</p></div><div class="el-ul"><ul>
<li data-line="0" dir="auto">Large sets of virtual registers that can hold register sets from independent threads</li>
<li data-line="1" dir="auto">Register renaming that provides unique register identifiers, allowing instructions from multiple threads to be mixed in the datapath without confusion</li>
<li data-line="2" dir="auto">Out-of-order completion that enables threads to execute out of order for better hardware utilization</li>
</ul></div><div class="el-p"><p dir="auto">Implementation primarily requires adding a per-thread renaming table and maintaining separate program counters. Independent commitment can be supported by logically keeping a separate reorder buffer for each thread.</p></div><div class="el-p"><p dir="auto">SMT allows the system to adapt dynamically to the environment. It can execute instructions from each thread when possible, while allowing a single thread to use all functional units if other threads experience long latency events. With more threads utilizing the issue capabilities of the CPU at each cycle, the exploitation of available resources is limited only by the imbalance between resource requests and availability.</p></div></div></div></div></div><div class="el-h2 heading-wrapper"><h2 data-heading="7. Comparing Multithreading Approaches" dir="auto" class="heading" id="7._Comparing_Multithreading_Approaches"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>7. Comparing Multithreading Approaches</h2><div class="heading-children"><div class="el-p"><p dir="auto">When comparing superscalar, fine-grained multithreading, coarse-grained multithreading, multiprocessing, and SMT in terms of processor cycle utilization:</p></div><div class="el-ul"><ul>
<li data-line="0" dir="auto">Superscalar processing shows many idle slots due to dependencies and stalls</li>
<li data-line="1" dir="auto">Fine-grained multithreading fills more slots but in a rigid, alternating pattern</li>
<li data-line="2" dir="auto">Coarse-grained multithreading shows blocks of execution from different threads</li>
<li data-line="3" dir="auto">Multiprocessing dedicates entire processors to specific threads</li>
<li data-line="4" dir="auto">SMT demonstrates the most efficient use of available slots by dynamically filling them with instructions from multiple threads</li>
</ul></div><div class="el-p"><p dir="auto">Performance generally improves as the number of threads increases, with SMT showing the best utilization of resources compared to other approaches.</p></div></div></div><div class="el-h2 heading-wrapper"><h2 data-heading="8. Beyond Single-Core Solutions" dir="auto" class="heading" id="8._Beyond_Single-Core_Solutions"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>8. Beyond Single-Core Solutions</h2><div class="heading-children"><div class="el-p"><p dir="auto">Continuing to increase performance and clock frequency of single cores has become increasingly difficult due to several challenges:</p></div><div class="el-ul"><ul>
<li data-line="0" dir="auto">Heat dissipation problems with deeper pipelines</li>
<li data-line="1" dir="auto">Speed-of-light transmission limitations in wires</li>
<li data-line="2" dir="auto">Growing complexity in design and verification</li>
<li data-line="3" dir="auto">Requirements for very large design teams</li>
</ul></div><div class="el-p"><p dir="auto">Meanwhile, many new applications are naturally multi-threaded, pushing the industry toward parallel solutions.</p></div></div></div><div class="el-h2 heading-wrapper"><h2 data-heading="9. The Shift to Parallel Architectures" dir="auto" class="heading" id="9._The_Shift_to_Parallel_Architectures"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>9. The Shift to Parallel Architectures</h2><div class="heading-children"><div class="el-p"><p dir="auto">While ILP architectures like superscalar and VLIW processors support fine-grained, instruction-level parallelism, they fail to effectively support large-scale parallel systems. Multiple-issue CPUs have become extremely complex, with diminishing returns in terms of extracting greater parallelism. This reality makes extracting parallelism at higher levels increasingly attractive.</p></div><div class="el-p"><p dir="auto">The next logical step is process- and thread-level parallel architectures. To achieve ever-greater performance, multiple microprocessors are connected in complex systems.</p></div><div class="el-p"><p dir="auto"><strong>Multiprocessing</strong> refers to using multiple processors within a computer system. The primary goal is to replicate processors to add performance, as opposed to designing a single faster processor. <strong>A parallel computer, which enables multiprocessing, is defined as a collection of processing elements that cooperates and communicate to solve large problems fast.</strong> Multiprocessing uses parallelism to allow multiple instruction streams to be executed simultaneously on different processors. Parallel architecture extends traditional computer architecture with a communication architecture</p></div><div class="el-p"><p dir="auto">In contrast to Instruction-Level Parallelism (ILP), which overlaps individual machine operations and is transparent to the user, parallel processing (multiprocessing) involves separate processors getting separate chunks of the program and is typically not transparent to the user</p></div></div></div><div class="el-h2 heading-wrapper"><h2 data-heading="10. Flynn's Taxonomy of Parallel Architectures" dir="auto" class="heading" id="10._Flynn's_Taxonomy_of_Parallel_Architectures"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>10. Flynn's Taxonomy of Parallel Architectures</h2><div class="heading-children"><div class="el-p"><p dir="auto">In 1966, Michael Flynn proposed a classification system for parallel architectures that remains relevant today:</p></div><div class="el-ol"><ol>
<li data-line="0" dir="auto"><strong>SISD (Single Instruction Single Data)</strong>: Traditional uniprocessor systems where a single instruction stream operates on a single data stream.</li>
<li data-line="2" dir="auto"><strong>MISD (Multiple Instruction Single Data)</strong>: A theoretical configuration with no practical implementations or commercial systems.</li>
<li data-line="4" dir="auto"><strong>SIMD (Single Instruction Multiple Data)</strong>: Systems where a single instruction is executed simultaneously on multiple data elements. These offer simple programming models, low overhead, flexibility, and can be implemented with custom integrated circuits.</li>
<li data-line="6" dir="auto"><strong>MIMD (Multiple Instruction Multiple Data)</strong>: Systems where multiple processors execute different instruction streams on different data. These are scalable, fault-tolerant, and can often be built using off-the-shelf microprocessors.</li>
</ol></div><div class="el-p"><p dir="auto">This taxonomy provides a framework for understanding the fundamental approaches to parallel computing architecture.</p></div></div></div><div class="el-h2 heading-wrapper"><h2 data-heading="Flynn's Taxonomy: Understanding Parallel Computing Models" dir="auto" class="heading" id="Flynn's_Taxonomy:_Understanding_Parallel_Computing_Models"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>Flynn's Taxonomy: Understanding Parallel Computing Models</h2><div class="heading-children"><div class="el-p"><p dir="auto">Flynn's taxonomy, proposed in 1966, provides a fundamental framework for classifying computer architectures based on instruction and data streams. This classification remains relevant today and helps us understand the different approaches to parallel computing.</p></div><div class="el-h3 heading-wrapper"><h3 data-heading="SISD: Single Instruction, Single Data" dir="auto" class="heading" id="SISD:_Single_Instruction,_Single_Data"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>SISD: Single Instruction, Single Data</h3><div class="heading-children"><div class="el-p"><p dir="auto">The SISD architecture represents traditional serial (non-parallel) computers. In this model, only one instruction stream is processed by the CPU during any clock cycle, and only one data stream is used as input. This creates a deterministic execution environment where operations occur in a predictable sequence. Despite the advances in parallel computing, SISD remains the oldest and most common type of computer architecture even today. It forms the basis of conventional sequential processing that we've used for decades.</p></div></div></div><div class="el-h3 heading-wrapper"><h3 data-heading="SIMD: Single Instruction, Multiple Data" dir="auto" class="heading" id="SIMD:_Single_Instruction,_Multiple_Data"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>SIMD: Single Instruction, Multiple Data</h3><div class="heading-children"><div class="el-p"><p dir="auto">SIMD represents a type of parallel computer where all processing units execute the same instruction at any given clock cycle, but each processing unit can operate on different data elements. This approach is particularly well-suited for specialized problems characterized by a high degree of regularity, such as graphics and image processing. The SIMD model received considerable attention during the 1980s, though today it's applied primarily in specific contexts like vector processors and multimedia instructions.</p></div><div class="el-p"><p dir="auto"><span alt="Multithreading and Multiprocessors.png" src="Multithreading and Multiprocessors.png" class="internal-embed media-embed image-embed is-loaded"><img alt="Multithreading and Multiprocessors.png" src="lib/media/multithreading-and-multiprocessors.png"></span></p></div><div class="el-p"><p dir="auto">The SIMD architecture features a central controller that broadcasts instructions to multiple processing elements (PEs). Each PE has its own data memory, while a single instruction memory and control processor handle fetching and dispatching instructions. The processors in SIMD systems are typically special-purpose, and the programming model is relatively simple. This architecture offers several advantages:</p></div><div class="el-ul"><ul>
<li data-line="0" dir="auto">Only one controller is needed for the entire array</li>
<li data-line="1" dir="auto">Only one copy of the program needs to be stored</li>
<li data-line="2" dir="auto">All computations are fully synchronized</li>
</ul></div><div class="el-p"><p dir="auto">In the SIMD model, all units are synchronized through a single Program Counter, though each unit has its own addressing registers that can reference different data addresses. The primary motivations for SIMD include sharing the cost of the control unit across all execution units and needing only one copy of the executing code. In practical implementations, SIMD systems often feature a mix of SISD instructions and SIMD instructions, with a host computer handling sequential operations and SIMD instructions being sent to all execution units, each with its own memory and registers, connected through an interconnection network for data exchange.</p></div><div class="el-p"><p dir="auto"><span alt="Multithreading and Multiprocessors-1.png" src="Multithreading and Multiprocessors-1.png" class="internal-embed media-embed image-embed is-loaded"><img alt="Multithreading and Multiprocessors-1.png" src="lib/media/multithreading-and-multiprocessors-1.png"></span></p></div><div class="el-h4 heading-wrapper"><h4 data-heading="Vector Processing: An Alternative to Traditional SIMD" dir="auto" class="heading" id="Vector_Processing:_An_Alternative_to_Traditional_SIMD"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>Vector Processing: An Alternative to Traditional SIMD</h4><div class="heading-children"><div class="el-p"><p dir="auto">Vector processing represents an alternative model to traditional SIMD architectures. Vector processors feature high-level operations that work on linear arrays of numbers called "vectors." While scalar processors perform operations on individual data elements (one operation at a time), vector processors perform the same operation on multiple data elements simultaneously.</p></div><div class="el-p"><p dir="auto"><span alt="Multithreading and Multiprocessors-2.png" src="Multithreading and Multiprocessors-2.png" class="internal-embed media-embed image-embed is-loaded"><img alt="Multithreading and Multiprocessors-2.png" src="lib/media/multithreading-and-multiprocessors-2.png"></span></p></div><div class="el-p"><p dir="auto">A vector processor typically consists of a pipelined scalar unit (which may be out-of-order or VLIW) combined with a vector unit. There are two main styles of vector architectures:</p></div><div class="el-ol"><ol>
<li data-line="0" dir="auto">Memory-memory vector processors: All vector operations are memory to memory</li>
<li data-line="1" dir="auto">Vector-register processors: All vector operations occur between vector registers (except load and store)</li>
</ol></div><div class="el-p"><p dir="auto">Vector-register processors are the vector equivalent of load-store architectures and include all vector machines developed since the late 1980s.</p></div><div class="el-p"><p dir="auto">The vector programming model utilises both scalar registers and vector registers. Vector registers contain multiple elements, and their operation is controlled by a Vector Length Register (VLR) that determines how many elements in the vector registers will be processed. Vector arithmetic instructions then perform operations across these elements in parallel.</p></div><div class="el-p"><p dir="auto"><span alt="Multithreading and Multiprocessors-3.png" src="Multithreading and Multiprocessors-3.png" class="internal-embed media-embed image-embed is-loaded"><img alt="Multithreading and Multiprocessors-3.png" src="lib/media/multithreading-and-multiprocessors-3.png"></span></p></div><div class="el-h5 heading-wrapper"><h5 data-heading="Vector Code Example" dir="auto" class="heading" id="Vector_Code_Example"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>Vector Code Example</h5><div class="heading-children"><div class="el-p"><p dir="auto">To illustrate the efficiency of vector processing, consider a simple loop that adds two arrays:</p></div><div class="el-pre"><pre><code data-line="0"># C code
for (i=0; i&lt;64; i++)
    C[i] = A[i] + B[i];
</code><button class="copy-code-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-copy"><rect x="8" y="8" width="14" height="14" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></pre></div><div class="el-p"><p dir="auto">In scalar code, this would require multiple instructions executed in a loop:</p></div><div class="el-pre"><pre><code data-line="0"># Scalar Code
LI R4, #64
loop:
    L.D F0, 0(R1)
    L.D F2, 0(R2)
    ADD.D F4, F2, F0
    S.D F4, 0(R3)
    DADDIU R1, 8
    DADDIU R2, 8
    DADDIU R3, 8
    DSUBIU R4, 1
    BNEZ R4, loop
</code><button class="copy-code-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-copy"><rect x="8" y="8" width="14" height="14" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></pre></div><div class="el-p"><p dir="auto">With vector instructions, the same operation becomes much more concise:</p></div><div class="el-pre"><pre><code data-line="0"># Vector Code
LI VLR, #64
LV V1, R1
LV V2, R2
ADDV.D V3, V1, V2
SV V3, R3
</code><button class="copy-code-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-copy"><rect x="8" y="8" width="14" height="14" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></pre></div><div class="el-p"><p dir="auto">Vector processing offers significant advantages in execution efficiency. It uses deep pipelines (enabling fast clock speeds) to execute element operations. The control of deep pipelines is simplified because elements in a vector are independent, eliminating hazards. Vector instructions can be executed using one pipelined functional unit or multiple units for even greater parallelism.</p></div><div class="el-p"><p dir="auto">The vector unit structure typically organizes vector registers into "lanes," with each lane handling specific elements (e.g., lane 1 processes elements 0, 4, 8, etc.). This structure facilitates efficient parallel processing of vector data.</p></div><div class="el-p"><p dir="auto">Contrary to common perception, vector applications extend far beyond scientific computing. They include:</p></div><div class="el-ul"><ul>
<li data-line="0" dir="auto">Multimedia processing (compression, graphics, audio synthesis, image processing)</li>
<li data-line="1" dir="auto">Standard benchmark kernels (Matrix Multiply, FFT, Convolution, Sort)</li>
<li data-line="2" dir="auto">Lossy and lossless compression</li>
<li data-line="3" dir="auto">Cryptography</li>
<li data-line="4" dir="auto">Speech and handwriting recognition</li>
<li data-line="5" dir="auto">Operating systems and networking functions</li>
<li data-line="6" dir="auto">Database operations</li>
<li data-line="7" dir="auto">Language runtime support</li>
<li data-line="8" dir="auto">And even general computing benchmarks like SPECint95</li>
</ul></div></div></div></div></div></div></div><div class="el-h3 heading-wrapper"><h3 data-heading="MISD: Multiple Instruction, Single Data" dir="auto" class="heading" id="MISD:_Multiple_Instruction,_Single_Data"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>MISD: Multiple Instruction, Single Data</h3><div class="heading-children"><div class="el-p"><p dir="auto">The MISD architecture represents a theoretical model where a single data stream is fed into multiple processing units, and each processing unit operates on the data independently via separate instruction streams. While included in Flynn's taxonomy for completeness, MISD has few practical implementations in commercial systems.</p></div></div></div><div class="el-h3 heading-wrapper"><h3 data-heading="MIMD: Multiple Instruction, Multiple Data" dir="auto" class="heading" id="MIMD:_Multiple_Instruction,_Multiple_Data"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>MIMD: Multiple Instruction, Multiple Data</h3><div class="heading-children"><div class="el-p"><p dir="auto"><a data-href="MIMD" href="universitÃ /aca/notes/mimd.html" class="internal-link" target="_self" rel="noopener nofollow">MIMD</a> has emerged as the architecture of choice for general-purpose multiprocessors and represents the most common type of parallel computer today. In this model, every processor may execute a different instruction stream and work with a different data stream. Execution can be synchronous or asynchronous, deterministic or non-deterministic, offering significant flexibility.</p></div><div class="el-p"><p dir="auto">The popularity of MIMD architectures stems from their versatility. They can function as single-user machines focused on high performance for specific applications, as multiprogrammed multiprocessors running many tasks simultaneously, or as some combination of these functions. Additionally, MIMD systems can be built using standard CPUs, making them cost-effective and easier to develop compared to specialized architectures.</p></div></div></div></div></div><div class="el-h2 heading-wrapper"><h2 data-heading="MIMD Architectures: The Dominant Parallel Computing Paradigm" dir="auto" class="heading" id="MIMD_Architectures:_The_Dominant_Parallel_Computing_Paradigm"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>MIMD Architectures: The Dominant Parallel Computing Paradigm</h2><div class="heading-children"><div class="el-p"><p dir="auto"><a data-tooltip-position="top" aria-label="MIMD" data-href="MIMD" href="universitÃ /aca/notes/mimd.html" class="internal-link" target="_self" rel="noopener nofollow">MIMD architectures</a>have become the dominant paradigm for parallel computing due to their flexibility and scalability. To effectively use a MIMD system with n processors, at least n threads or processes must be executed. These independent threads are typically identified by the programmer or created by the compiler, with parallelism contained within the threads themselvesâa concept known as thread-level parallelism.</p></div><div class="el-p"><p dir="auto">A thread in MIMD can range from a large, independent process to parallel iterations of a loop. Importantly, parallelism in MIMD systems is identified by software rather than hardware (as in superscalar CPUs), representing a fundamental shift in how parallel computation is organized and managed.</p></div><div class="el-p"><p dir="auto">Existing MIMD machines fall into two main categories based on the number of processors involved, which in turn dictates memory organization and interconnection strategies:</p></div><div class="el-ol"><ol>
<li data-line="0" dir="auto"><div class="list-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>
<p><strong>Centralized shared-memory architectures</strong>:</p>
<ul>
<li data-line="2" dir="auto">Typically contain at most a few dozen processor chips (less than 100 cores)</li>
<li data-line="3" dir="auto">Feature large caches and single memory with multiple banks</li>
<li data-line="4" dir="auto">Often called Symmetric Multiprocessors (SMP)</li>
<li data-line="5" dir="auto">Use a Uniform Memory Access (UMA) architecture where all processors have equal access time to memory</li>
</ul>
</li>
<li data-line="6" dir="auto"><div class="list-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>
<p><strong>Distributed memory architectures</strong>:</p>
<ul>
<li data-line="8" dir="auto">Designed to support large processor counts</li>
<li data-line="9" dir="auto">Require high-bandwidth interconnect systems</li>
<li data-line="10" dir="auto">Each node contains a processor with its own cache and main memory</li>
<li data-line="11" dir="auto">Main disadvantage: the complexity of data communication among processors</li>
</ul>
</li>
</ol></div><div class="el-p"><p dir="auto">The Tilera architecture is presented in the document as an example of a modern MIMD implementation, though specific details aren't elaborated.</p></div></div></div><div class="el-h2 heading-wrapper"><h2 data-heading="4. Key Design Considerations for Multiprocessor Systems" dir="auto" class="heading" id="4._Key_Design_Considerations_for_Multiprocessor_Systems"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>4. Key Design Considerations for Multiprocessor Systems</h2><div class="heading-children"><div class="el-p"><p dir="auto">Designing effective multiprocessor systems involves addressing several critical issues:</p></div><div class="el-ol"><ol>
<li data-line="0" dir="auto"><strong>Processor quantity and capability</strong>: Determining how many processors to include and how powerful each should be</li>
<li data-line="1" dir="auto"><strong>Data sharing mechanisms</strong>: Establishing how parallel processors share data</li>
<li data-line="2" dir="auto"><strong>Memory placement</strong>: Deciding where to place physical memory within the system</li>
<li data-line="3" dir="auto"><strong>Coordination mechanisms</strong>: Implementing how parallel processors cooperate and coordinate activities</li>
<li data-line="4" dir="auto"><strong>Interconnection topology</strong>: Selecting the appropriate network structure to connect processors</li>
<li data-line="5" dir="auto"><strong>Programming model</strong>: Choosing how to program the processors for effective parallel execution</li>
<li data-line="6" dir="auto"><strong>Cache coherency</strong>: Maintaining consistent cache states across multiple processors</li>
<li data-line="7" dir="auto"><strong>Memory consistency</strong>: Ensuring proper ordering of memory operations across the system</li>
<li data-line="8" dir="auto"><strong>Performance evaluation</strong>: Developing metrics and methods to assess system performance</li>
</ol></div><div class="el-p"><p dir="auto">These considerations form the foundation for multiprocessor system design and represent the key challenges that architects must address when developing parallel computing platforms.</p></div><div class="mod-footer mod-ui"></div></div></div></div></div></div><div class="sidebar-right sidebar"><div class="sidebar-handle"></div><div class="sidebar-topbar"><div class="topbar-content"></div><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div><div class="sidebar-content"><div class="graph-view-wrapper"><div class="sidebar-section-header">Interactive Graph</div><div class="graph-view-placeholder">
		<div class="graph-view-container">
			<div class="graph-icon graph-expand" role="button" aria-label="Expand" data-tooltip-position="top"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><line x1="7" y1="17" x2="17" y2="7"></line><polyline points="7 7 17 7 17 17"></polyline></svg></div>
			<canvas id="graph-canvas" class="hide" width="512px" height="512px"></canvas>
		</div>
		</div></div><div class="tree-container mod-root nav-folder tree-item outline-tree" data-depth="0"><div class="tree-header"><span class="sidebar-section-header">Table Of Contents</span><button class="clickable-icon collapse-tree-button" aria-label="Collapse All"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></svg></button></div><div class="tree-scroll-area tree-item-children nav-folder-children"><div class="tree-item mod-tree-folder nav-folder mod-collapsible is-collapsed" style="display: none;"></div><div class="tree-item" data-depth="1"><a class="tree-link" href="universitÃ /aca/notes/multithreading-and-multiprocessors.html#Multithreading and Multiprocessors"><div class="tree-item-contents heading-link" heading-name="Multithreading and Multiprocessors"><span class="tree-item-title">Multithreading and Multiprocessors</span></div></a><div class="tree-item-children nav-folder-children"><div class="tree-item" data-depth="2"><a class="tree-link" href="universitÃ /aca/notes/multithreading-and-multiprocessors.html#1._The_Evolution_of_Processor_Performance"><div class="tree-item-contents heading-link" heading-name="1. The Evolution of Processor Performance"><span class="tree-item-title">1. 
The Evolution of Processor Performance
</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="2"><a class="tree-link" href="universitÃ /aca/notes/multithreading-and-multiprocessors.html#2._Why_Traditional_Processors_Hit_Performance_Limits"><div class="tree-item-contents heading-link" heading-name="2. Why Traditional Processors Hit Performance Limits"><span class="tree-item-title">2. 
Why Traditional Processors Hit Performance Limits
</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="2"><a class="tree-link" href="universitÃ /aca/notes/multithreading-and-multiprocessors.html#3._Parallel_Programming:_The_Fundamental_Concepts"><div class="tree-item-contents heading-link" heading-name="3. Parallel Programming: The Fundamental Concepts"><span class="tree-item-title">3. 
Parallel Programming: The Fundamental Concepts
</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="2"><a class="tree-link" href="universitÃ /aca/notes/multithreading-and-multiprocessors.html#4._Understanding_Multithreaded_Execution"><div class="tree-item-contents heading-link" heading-name="4. Understanding Multithreaded Execution"><span class="tree-item-title">4. 
Understanding Multithreaded Execution
</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item mod-collapsible" data-depth="2"><a class="tree-link" href="universitÃ /aca/notes/multithreading-and-multiprocessors.html#5._Thread-Level_Parallelism_(TLP)_Approaches"><div class="tree-item-contents heading-link" heading-name="5. Thread-Level Parallelism (TLP) Approaches"><div class="collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><span class="tree-item-title">5. 
Thread-Level Parallelism (TLP) Approaches
</span></div></a><div class="tree-item-children nav-folder-children"><div class="tree-item" data-depth="3"><a class="tree-link" href="universitÃ /aca/notes/multithreading-and-multiprocessors.html#Fine-Grained_Multithreading"><div class="tree-item-contents heading-link" heading-name="Fine-Grained Multithreading"><span class="tree-item-title">Fine-Grained Multithreading</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="3"><a class="tree-link" href="universitÃ /aca/notes/multithreading-and-multiprocessors.html#Coarse-Grained_Multithreading"><div class="tree-item-contents heading-link" heading-name="Coarse-Grained Multithreading"><span class="tree-item-title">Coarse-Grained Multithreading</span></div></a><div class="tree-item-children nav-folder-children"></div></div></div></div><div class="tree-item mod-collapsible" data-depth="2"><a class="tree-link" href="universitÃ /aca/notes/multithreading-and-multiprocessors.html#6._Combining_ILP_and_TLP:_Simultaneous_Multithreading"><div class="tree-item-contents heading-link" heading-name="6. Combining ILP and TLP: Simultaneous Multithreading"><div class="collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><span class="tree-item-title">6. 
Combining ILP and TLP: Simultaneous Multithreading
</span></div></a><div class="tree-item-children nav-folder-children"><div class="tree-item" data-depth="3"><a class="tree-link" href="universitÃ /aca/notes/multithreading-and-multiprocessors.html#How_SMT_Works"><div class="tree-item-contents heading-link" heading-name="How SMT Works"><span class="tree-item-title">How SMT Works</span></div></a><div class="tree-item-children nav-folder-children"></div></div></div></div><div class="tree-item" data-depth="2"><a class="tree-link" href="universitÃ /aca/notes/multithreading-and-multiprocessors.html#7._Comparing_Multithreading_Approaches"><div class="tree-item-contents heading-link" heading-name="7. Comparing Multithreading Approaches"><span class="tree-item-title">7. 
Comparing Multithreading Approaches
</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="2"><a class="tree-link" href="universitÃ /aca/notes/multithreading-and-multiprocessors.html#8._Beyond_Single-Core_Solutions"><div class="tree-item-contents heading-link" heading-name="8. Beyond Single-Core Solutions"><span class="tree-item-title">8. 
Beyond Single-Core Solutions
</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="2"><a class="tree-link" href="universitÃ /aca/notes/multithreading-and-multiprocessors.html#9._The_Shift_to_Parallel_Architectures"><div class="tree-item-contents heading-link" heading-name="9. The Shift to Parallel Architectures"><span class="tree-item-title">9. 
The Shift to Parallel Architectures
</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="2"><a class="tree-link" href="universitÃ /aca/notes/multithreading-and-multiprocessors.html#10._Flynn's_Taxonomy_of_Parallel_Architectures"><div class="tree-item-contents heading-link" heading-name="10. Flynn's Taxonomy of Parallel Architectures"><span class="tree-item-title">10. 
Flynn's Taxonomy of Parallel Architectures
</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item mod-collapsible" data-depth="2"><a class="tree-link" href="universitÃ /aca/notes/multithreading-and-multiprocessors.html#Flynn's_Taxonomy:_Understanding_Parallel_Computing_Models"><div class="tree-item-contents heading-link" heading-name="Flynn's Taxonomy: Understanding Parallel Computing Models"><div class="collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><span class="tree-item-title">Flynn's Taxonomy: Understanding Parallel Computing Models</span></div></a><div class="tree-item-children nav-folder-children"><div class="tree-item" data-depth="3"><a class="tree-link" href="universitÃ /aca/notes/multithreading-and-multiprocessors.html#SISD:_Single_Instruction,_Single_Data"><div class="tree-item-contents heading-link" heading-name="SISD: Single Instruction, Single Data"><span class="tree-item-title">SISD: Single Instruction, Single Data</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item mod-collapsible" data-depth="3"><a class="tree-link" href="universitÃ /aca/notes/multithreading-and-multiprocessors.html#SIMD:_Single_Instruction,_Multiple_Data"><div class="tree-item-contents heading-link" heading-name="SIMD: Single Instruction, Multiple Data"><div class="collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><span class="tree-item-title">SIMD: Single Instruction, Multiple Data</span></div></a><div class="tree-item-children nav-folder-children"><div class="tree-item mod-collapsible" data-depth="4"><a class="tree-link" href="universitÃ /aca/notes/multithreading-and-multiprocessors.html#Vector_Processing:_An_Alternative_to_Traditional_SIMD"><div class="tree-item-contents heading-link" heading-name="Vector Processing: An Alternative to Traditional SIMD"><div class="collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><span class="tree-item-title">Vector Processing: An Alternative to Traditional SIMD</span></div></a><div class="tree-item-children nav-folder-children"><div class="tree-item" data-depth="5"><a class="tree-link" href="universitÃ /aca/notes/multithreading-and-multiprocessors.html#Vector_Code_Example"><div class="tree-item-contents heading-link" heading-name="Vector Code Example"><span class="tree-item-title">Vector Code Example</span></div></a><div class="tree-item-children nav-folder-children"></div></div></div></div></div></div><div class="tree-item" data-depth="3"><a class="tree-link" href="universitÃ /aca/notes/multithreading-and-multiprocessors.html#MISD:_Multiple_Instruction,_Single_Data"><div class="tree-item-contents heading-link" heading-name="MISD: Multiple Instruction, Single Data"><span class="tree-item-title">MISD: Multiple Instruction, Single Data</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="3"><a class="tree-link" href="universitÃ /aca/notes/multithreading-and-multiprocessors.html#MIMD:_Multiple_Instruction,_Multiple_Data"><div class="tree-item-contents heading-link" heading-name="MIMD: Multiple Instruction, Multiple Data"><span class="tree-item-title">MIMD: Multiple Instruction, Multiple Data</span></div></a><div class="tree-item-children nav-folder-children"></div></div></div></div><div class="tree-item" data-depth="2"><a class="tree-link" href="universitÃ /aca/notes/multithreading-and-multiprocessors.html#MIMD_Architectures:_The_Dominant_Parallel_Computing_Paradigm"><div class="tree-item-contents heading-link" heading-name="MIMD Architectures: The Dominant Parallel Computing Paradigm"><span class="tree-item-title">MIMD Architectures: The Dominant Parallel Computing Paradigm</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="2"><a class="tree-link" href="universitÃ /aca/notes/multithreading-and-multiprocessors.html#4._Key_Design_Considerations_for_Multiprocessor_Systems"><div class="tree-item-contents heading-link" heading-name="4. Key Design Considerations for Multiprocessor Systems"><span class="tree-item-title">4. 
Key Design Considerations for Multiprocessor Systems
</span></div></a><div class="tree-item-children nav-folder-children"></div></div></div></div></div></div></div><script defer="">let rs = document.querySelector(".sidebar-right"); rs.classList.add("is-collapsed"); if (window.innerWidth > 768) rs.classList.remove("is-collapsed"); rs.style.setProperty("--sidebar-width", localStorage.getItem("sidebar-right-width"));</script></div></div></body></html>